# Testing Guide for Code Writing

Condensed testing rules for TDD workflow. For full testing strategy, see `~/.claude/skills/test-master/SKILL.md`.

---

## Test Quality Rules (apply when writing any test)

### Litmus Test
Before finishing any test, ask: "If I remove the core logic line being tested, does this test still pass?"
If yes — test is useless. Rewrite.

### Real Data Over Mocks
Priority order:
1. Real dependencies (test DB, real file system) → integration test
2. Minimal mocks (1-2 external services) → unit test
3. Heavy mocking (3+) → wrong test type, switch to integration

### No Mock-Return Pattern
```python
# BAD — tests mock, not code
mock_service.get_data.return_value = 42
result = await handler()
assert result == 42

# GOOD — tests actual computation
result = calculate_total(100, 0.2)
assert result == 80.0
```

### Test the Contract
```python
# BAD — tests implementation detail
mock_db.execute.assert_called_with('SELECT * FROM users WHERE id = 1')

# GOOD — tests what goes in → what comes out
user = await get_user(1)
assert user.name == 'Alice'
```

---

## Decision: Do I Need Tests?

**YES — write tests for:**
- Business logic (calculations, validations, transforms)
- Decision-making code (if/else, switch, state machines)
- Data processing and formatting
- Error handling logic

**NO — skip tests for:**
- Simple getters/setters
- One-line text or config changes
- Trivial updates with no logic

## Decision: Which Test Type?

| Type | When to Use | Mock Strategy |
|------|-------------|---------------|
| **Unit** | Business logic, pure functions, validations | Mock DB, APIs, file system, time |
| **Integration** | API endpoints, DB operations, external services | Real DB (test), mock external services |
| **E2E** | Critical user journeys (auth, payment, core flows) | Real everything (use sandbox/test mode) |

**Rule:** If mocking >3 dependencies → wrong test type. Use integration or E2E instead.

**When to Prioritize E2E over Unit:**
- UI apps → E2E + Integration > Unit
- Browser extensions → E2E (real browser) > Unit
- CLI tools → Unit + Integration
- API/Backend → Unit + Integration

## TDD Flow

```
1. Write tests for requirements + edge cases
2. Run tests → all should FAIL (no implementation)
3. Write code to make tests pass
4. Run tests → all should PASS
5. Refactor if needed (tests stay green)
```

## Writing Good Tests

**DO:**
- One test = one scenario (happy path, error case, edge case — separate tests)
- Test behavior, not implementation details
- Use descriptive names: `test_user_creation_fails_when_email_invalid`
- Test actual results: `expect(calculateTotal(100, 0.2)).toBe(80)`
- Test real state changes: `cart.add({id: 1}); expect(cart.items).toHaveLength(1)`
- Keep tests fast: unit < 100ms, integration < 1s

**Write quality tests:**
- Write meaningful assertions that verify actual behavior
- Verify results, not just that mock was called
- Add assertions when rendering components
- Keep tests independent — each test sets up its own state
- Isolate test state — each test manages its own data

## Test Structure Pattern

```
// Arrange — set up test data and conditions
// Act — execute the function/action being tested
// Assert — verify the result
```

Group tests by feature or function. Use `class Test*` for grouping, `def test_*` for individual cases (pytest). For JS/TS: `describe` blocks with `it`/`test`.

## What test-reviewer Checks

The test-reviewer agent will verify:
- Tests have meaningful assertions (not trivial)
- Tests cover requirements and edge cases
- Test names are descriptive
- Mocking is appropriate (not excessive)
- Tests are independent and isolated
- Test pyramid is balanced for the feature
